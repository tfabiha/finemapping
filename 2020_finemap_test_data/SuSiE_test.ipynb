{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# SuSiE RSS\n",
    "\n",
    "Bayesian sum of single-effect (SuSiE) linear regression using z scores\n",
    "\n",
    "After applying LD_Clumping.ipynb and Region_Extraction.ipynb to select regions that overlap between traits, the current pipeline focuses on SuSiE to do fine mapping of those regions to see if theres something of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To run this notebook follow the example:\n",
    "\n",
    "```\n",
    "sos run ~/project/UKBB_GWAS_dev/workflow/SuSiE_test.ipynb \\\n",
    "    --cwd output \\\n",
    "    --region_dir /gpfs/gibbs/pi/dewan/data/UKBiobank/results/region_extraction/f3393_hearing_aid \\\n",
    "    --region_file /gpfs/gibbs/pi/dewan/data/UKBiobank/results/LD_clumping/f3393_hearing_aid/200828_UKBB_Hearing_aid_f3393_hearing_aid_cat.fastGWA.snp_stats.clumped_region \\\n",
    "    --sumstats_path /gpfs/gibbs/pi/dewan/data/UKBiobank/results/FastGWA_results/results_imputed_data/f3393_hearing_aid/*.snp_stats.gz \\\n",
    "    --N 230411 \\\n",
    "    --container_lmm /gpfs/gibbs/pi/dewan/data/UKBiobank/lmm.sif\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to region extraction files\n",
    "parameter: region_dir = path\n",
    "#The region file after LD clumping\n",
    "parameter: region_file = path\n",
    "parameter: sumstats_path = path\n",
    "fail_if(not region_file.is_file(), msg = 'Cannot find regions to fine map. Please specify them using ``--region-file`` option.')\n",
    "# Load all regions of interest. Each item in the list will be a region: (chr, start, end)\n",
    "regions = [x.strip() for x in open(region_file).readlines()]\n",
    "regions = [x.replace(' ', '_' ) for x in regions]\n",
    "#The directory for output files\n",
    "parameter: cwd = path\n",
    "## The container with the lmm/marp software. Can be either a dockerhub image or a singularity `sif` file.\n",
    "#parameter: container_lmm = '/home/hs863/LMM/lmm_v_1_3.sif'\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.4'\n",
    "parameter: container_marp = 'gaow/marp'\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_1]\n",
    "parameter: N = int\n",
    "input: [(f\"{region_dir}/{x}/{sumstats_path:bn}.all_chr_{x}.sumstats.gz\", f\"{region_dir}/{x}/{sumstats_path:bn}.all_chr_{x}.sample_ld.gz\") for x in regions], group_by = 2\n",
    "output: [f'{cwd}/{x}.{sumstats_path:bnn}.SuSiE_RSS.rds' for x in regions], group_by=1\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '20G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    sumstat = read.csv(${_input[0]:r}, sep = '\\t', header=T,stringsAsFactors=F)\n",
    "    ld = read.csv(${_input[1]:r}, sep = '\\t', header=T, stringsAsFactors=F)\n",
    "    ld = as.matrix(ld[,-1])\n",
    "    print(dim(as.double(sumstat$Z)))\n",
    "    res = susieR::susie_rss(as.double(sumstat$Z), ld, z_ld_weight = 1/${N}, \n",
    "                            L = 10,\n",
    "                            estimate_residual_variance = TRUE, check_R=F,\n",
    "                            estimate_prior_variance = TRUE, check_z = F)\n",
    "\n",
    "    res$pos = as.integer(sumstat$POS)\n",
    "    res$z = as.double(sumstat$Z)\n",
    "    res$p = as.double(sumstat$P)\n",
    "    res$var_names = sumstat$SNP\n",
    "    \n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_2]\n",
    "output: pip_plot = f\"{cwd}/{_input:bn}.png\", test = f\"{cwd}/{_input:bn}.md\", group_by=2\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '12h', mem = '20G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container_lmm, expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    res = readRDS(${_input:r})\n",
    "    png(${_output[0]:r}, width = 8, height=5, unit='in', res=300)\n",
    "    susieR::susie_plot(res, y= \"PIP\", pos=list(attr='pos',start=res$pos[1],end=res$pos[length(res$pos)]), add_legend=T)\n",
    "    dev.off()\n",
    "R: container=container_lmm, expand = \"${ }\", stderr = f'{_output[1]:n}.stderr', stdout = f'{_output[1]:n}.stdout'\n",
    "    res = readRDS(${_input:r})\n",
    "    cs_mat <- do.call(rbind, lapply(res$sets$cs, \n",
    "                           function(x) paste(x,collapse=\" \")\n",
    "                           )\n",
    "             )\n",
    "\n",
    "    s <- \"${_output[1]:bn}\"\n",
    "    tem <- strsplit(s, \"\\\\.\")[[1]][1]\n",
    "    \n",
    "    write(dim(cs_mat)[1], ${_output[1]:r})\n",
    "    write.table(cs_mat, ${_output[1]:r}, append = TRUE, row.names = TRUE)\n",
    "    \n",
    "    write(\"purity\", ${_output[1]:r}, append = TRUE)\n",
    "    write.table(res$sets$purity, ${_output[1]:r}, append = TRUE, row.names = TRUE)\n",
    "    \n",
    "    for (i in res$sets$cs) {\n",
    "        z3 <- cbind(i,res$pip[i])\n",
    "        colnames(z3) <- c('position', 'PIP')\n",
    "        z3[order(z3[,2], decreasing = TRUE),]\n",
    "        \n",
    "        write(\"lsmthn\", ${_output[1]:r}, append = TRUE)\n",
    "        write.table(z3, ${_output[1]:r}, append = TRUE, row.names = FALSE, col.names = TRUE)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_3]\n",
    "sep = '\\n\\n---\\n'\n",
    "cw = '{cwd}/'\n",
    "input: group_by = 'all'\n",
    "output: analysis_summary = f'{cwd}/{sumstats_path:bnn}.analysis_summary.md'\n",
    "python: container=container_lmm, expand = \"${ }\"\n",
    "\n",
    "    theme = '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "     p {\n",
    "       font-size: 24px;\n",
    "       height: 900px;\n",
    "       margin-top:1cm;\n",
    "      }\n",
    "      img {\n",
    "        height: 70%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "      body {\n",
    "       margin-top: auto;\n",
    "       margin-bottom: auto;\n",
    "       font-family: verdana;\n",
    "      }\n",
    "    ---    \n",
    "    '''\n",
    "    import numpy\n",
    "    \n",
    "    def f7(seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "    text = \"\"\n",
    "    sep = '\\n\\n---\\n'\n",
    "    inp = \"${_input:r}\".split(\" \")\n",
    "    for i, each in enumerate(inp):\n",
    "        inp[i] = \".\".join(each.split(\".\")[:-1])\n",
    "\n",
    "    r = f7(\"${_input:bn}\".split(\" \"))\n",
    "    \n",
    "    num_csets = []\n",
    "    region_info = []\n",
    "\n",
    "    for i, each in enumerate(f7(inp)):\n",
    "        text_temp = \"\"\n",
    "        text_temp += \"#\\n\\n Susie RSS {region} \\n\".format(region=r[i])\n",
    "        text_temp += \"![]({region}.png){sep} \\n \\n\".format(region=r[i], sep=sep)\n",
    "\n",
    "        f = open(each[1:]+\".md\", \"r\")\n",
    "        num_csets.append(int(f.readline()))\n",
    "        print(num_csets)\n",
    "        \n",
    "        if num_csets[i] > 0:\n",
    "            f.readline()\n",
    "\n",
    "            csets = [f.readline().strip(\"\\n\").split(\" \") for n in range(num_csets[i])]\n",
    "            for j in range(len(csets)):\n",
    "                csets[j] = [ x.strip(\"\\\"\") for x in csets[j]]\n",
    "\n",
    "            print(csets)\n",
    "\n",
    "            table = \"\"\n",
    "            table += \"| credible set | positions | \\n\"\n",
    "            table += \"| --- | --- | \\n\"\n",
    "            for j in range(len(csets)):\n",
    "                table += \"| {} | {} | \\n\".format(csets[j][0], \", \".join(csets[j][1:]))\n",
    "\n",
    "            text_temp += table + sep\n",
    "\n",
    "            f.readline()\n",
    "            f.readline()\n",
    "            table = \"|  | min.abs.corr | mean.abs.corr | median.abs.corr | \\n\"\n",
    "            table += \"| --- | --- | --- | --- | \\n\"\n",
    "            for j in range(len(csets)):\n",
    "                row = [ x.strip(\"\\\"\") for x in f.readline().strip(\"\\n\").split(\" \")]\n",
    "                table += \"| {} | {} | {} | {} | \\n\".format(row[0], row[1], row[2], row[3])\n",
    "\n",
    "            text_temp += table + sep\n",
    "\n",
    "            for j in range(len(csets)):\n",
    "                table = \"\"#\"{}\".format(csets[j][0]) + \"\\n\"\n",
    "                table += \"| {} position | PIP | \\n\".format(csets[j][0])\n",
    "                table += \"| --- | --- | \\n\"\n",
    "                f.readline() \n",
    "                f.readline()\n",
    "\n",
    "                for pos in csets[j][1:]:\n",
    "                    row = f.readline().strip(\"\\n\").split(\" \")\n",
    "                    table += \"| {} | {} | \\n\".format(row[0], row[1])\n",
    "\n",
    "                text_temp += table + sep\n",
    "        region_info.append(text_temp)\n",
    "            \n",
    "        \n",
    "        f.close()\n",
    "    f = open(\"${_output}\", \"w\")\n",
    "    \n",
    "    cset_order = numpy.argsort(num_csets)\n",
    "    #cset_order = cser_order.tolist()\n",
    "    #cset_order.reverse()\n",
    "    for c in cset_order:\n",
    "        text += region_info[c]\n",
    "    \n",
    "    f.write(theme + text)\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate analysis report: HTML file, and optionally PPTX file\n",
    "[default_4]\n",
    "output: f\"{_input['analysis_summary']:n}.html\"\n",
    "sh: container=container_marp, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    node /opt/marp/.cli/marp-cli.js ${_input['analysis_summary']} -o ${_output:a} \\\n",
    "        --title '${region_file:bnn} fine mapping analysis' \\\n",
    "        --allow-local-files\n",
    "    node /opt/marp/.cli/marp-cli.js ${_input['analysis_summary']} -o ${_output:an}.pptx \\\n",
    "        --title '${region_file:bnn} fine mapping analysis' \\\n",
    "        --allow-local-files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.20.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
